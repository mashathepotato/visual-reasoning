{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaeea05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/masha/Documents/visual-reasoning\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/masha/Documents/visual-reasoning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94e42ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "DEVICE = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "MODEL_PATH = 'models/rotator_l2_100e_10k.pth'\n",
    "print('DEVICE:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ac3f3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHIRAL_SHAPES = {\n",
    "    'L': [(0,-1),(0,0),(0,1),(1,1)],\n",
    "    'Z': [(0,0),(-1,0),(0,1),(1,1)],\n",
    "    'S': [(0,0),(1,0),(0,1),(-1,1)],\n",
    "}\n",
    "\n",
    "def draw_shape_np(name, size=64):\n",
    "    img = np.zeros((size, size), dtype=np.uint8)\n",
    "    center = size // 2\n",
    "    block = size // 8\n",
    "    for dx, dy in CHIRAL_SHAPES[name]:\n",
    "        x = center + dx * block - block // 2\n",
    "        y = center + dy * block - block // 2\n",
    "        cv2.rectangle(img, (x, y), (x + block, y + block), 255, -1)\n",
    "    return img\n",
    "\n",
    "def norm_tensor(x):\n",
    "    return (torch.tensor(x).float().unsqueeze(0) / 255.0 - 0.5) / 0.5\n",
    "\n",
    "class PairDataset(Dataset):\n",
    "    def __init__(self, n=1000):\n",
    "        self.n = n\n",
    "    def __len__(self): return self.n\n",
    "    def __getitem__(self, idx):\n",
    "        key = random.choice(list(CHIRAL_SHAPES.keys()))\n",
    "        base_np = draw_shape_np(key, 64)\n",
    "        angle = random.randint(0, 359)\n",
    "        M = cv2.getRotationMatrix2D((32, 32), angle, 1.0)\n",
    "        is_same = (random.random() > 0.5)\n",
    "        if is_same:\n",
    "            target_np = cv2.warpAffine(base_np, M, (64, 64))\n",
    "            label = 1.0\n",
    "        else:\n",
    "            target_np = cv2.warpAffine(cv2.flip(base_np, 1), M, (64, 64))\n",
    "            label = 0.0\n",
    "        return norm_tensor(base_np), norm_tensor(target_np), torch.tensor([label]).float()\n",
    "\n",
    "train_loader = DataLoader(PairDataset(2000), batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(PairDataset(400), batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92697732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Rotator (same as exhaustive search) ---\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class FastRotator(nn.Module):\n",
    "    def __init__(self, backbone_dim=384, flow_dim=32):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Sequential(nn.Linear(1, flow_dim*4), nn.GELU(), nn.Linear(flow_dim*4, flow_dim*4))\n",
    "        self.angle_mlp = nn.Sequential(nn.Linear(1, flow_dim*4), nn.GELU(), nn.Linear(flow_dim*4, flow_dim*4))\n",
    "        self.cond_proj = nn.Linear(backbone_dim, flow_dim*4)\n",
    "\n",
    "        self.inc = DoubleConv(1, flow_dim)\n",
    "        self.down1 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(flow_dim, flow_dim*2))\n",
    "        self.down2 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(flow_dim*2, flow_dim*4))\n",
    "\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv1 = DoubleConv(flow_dim*6, flow_dim*2)\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv2 = DoubleConv(flow_dim*3, flow_dim)\n",
    "\n",
    "        self.outc = nn.Conv2d(flow_dim, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x_t, t, dino_emb, target_angle_deg):\n",
    "        t_emb = self.time_mlp(t)\n",
    "        d_emb = self.cond_proj(dino_emb)\n",
    "        a_emb = self.angle_mlp(target_angle_deg / 360.0)\n",
    "        global_cond = (t_emb + d_emb + a_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        x1 = self.inc(x_t)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x3 = x3 + global_cond\n",
    "\n",
    "        x = self.conv1(torch.cat([self.up1(x3), x2], dim=1))\n",
    "        x = self.conv2(torch.cat([self.up2(x), x1], dim=1))\n",
    "        return self.outc(x)\n",
    "\n",
    "rotator = FastRotator().to(DEVICE)\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    raise FileNotFoundError(MODEL_PATH)\n",
    "rotator.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "rotator.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def apply_rotation(model, base_img, base_emb, angle_deg, steps=10):\n",
    "    model.eval()\n",
    "    dt = 1.0 / steps\n",
    "    curr = base_img.clone()\n",
    "    B = base_img.shape[0]\n",
    "    if torch.is_tensor(angle_deg):\n",
    "        target_ang = angle_deg.to(DEVICE)\n",
    "        if target_ang.ndim == 1:\n",
    "            target_ang = target_ang.view(-1, 1)\n",
    "    else:\n",
    "        target_ang = torch.full((B, 1), angle_deg, device=DEVICE)\n",
    "    for i in range(steps):\n",
    "        t = torch.full((B, 1), i/steps, device=DEVICE)\n",
    "        v = model(curr, t, base_emb, target_ang)\n",
    "        curr = curr + v * dt\n",
    "    return curr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1fdd664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reasoning model: encoder + controller + rotator-in-the-loop ---\n",
    "class TinyEncoder(nn.Module):\n",
    "    def __init__(self, in_ch=1, dim=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, dim, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(dim, dim, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(dim, dim, 3, padding=1), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1,1))\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1).squeeze(-1)\n",
    "\n",
    "class Controller(nn.Module):\n",
    "    def __init__(self, dim=64):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim*2, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "    def forward(self, h_state, h_target):\n",
    "        return self.mlp(torch.cat([h_state, h_target], dim=-1))\n",
    "\n",
    "class Reasoner(nn.Module):\n",
    "    def __init__(self, steps=8, enc_dim=64):\n",
    "        super().__init__()\n",
    "        self.steps = steps\n",
    "        self.encoder = TinyEncoder(dim=enc_dim)\n",
    "        self.controller = Controller(dim=enc_dim)\n",
    "        self.to_rotator = nn.Linear(enc_dim, 384)\n",
    "        self.head = nn.Sequential(nn.Linear(enc_dim, 64), nn.ReLU(), nn.Linear(64, 1))\n",
    "\n",
    "    def forward(self, img_a, img_b):\n",
    "        # Encode target once\n",
    "        h_target = self.encoder(img_b)\n",
    "\n",
    "        # Initialize state\n",
    "        curr = img_a\n",
    "        h_state = self.encoder(curr)\n",
    "\n",
    "        # Unroll rotation reasoning\n",
    "        for _ in range(self.steps):\n",
    "            delta = self.controller(h_state, h_target)\n",
    "            # clamp to keep small steps (degrees)\n",
    "            delta = torch.clamp(delta, -30.0, 30.0)\n",
    "            rot_emb = self.to_rotator(h_state).detach()\n",
    "            curr = apply_rotation(rotator, curr, rot_emb, delta, steps=10)\n",
    "            h_state = self.encoder(curr)\n",
    "\n",
    "        # Decision head\n",
    "        logits = self.head(h_state)\n",
    "        return logits\n",
    "\n",
    "reasoner = Reasoner(steps=8).to(DEVICE)\n",
    "opt = torch.optim.Adam(reasoner.parameters(), lr=1e-3)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da167600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=0.6939\n",
      "Epoch 2: loss=0.6930\n",
      "Epoch 3: loss=0.6934\n",
      "Epoch 4: loss=0.6934\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    reasoner.train()\n",
    "    total = 0.0\n",
    "    for img_a, img_b, label in train_loader:\n",
    "        img_a = img_a.to(DEVICE)\n",
    "        img_b = img_b.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "\n",
    "        logits = reasoner(img_a, img_b)\n",
    "        loss = loss_fn(logits, label)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total += loss.item()\n",
    "    print(f'Epoch {epoch+1}: loss={total/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297d2a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Eval ---\n",
    "reasoner.eval()\n",
    "y_true = []\n",
    "y_scores = []\n",
    "with torch.no_grad():\n",
    "    for img_a, img_b, label in test_loader:\n",
    "        img_a = img_a.to(DEVICE)\n",
    "        img_b = img_b.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        logits = reasoner(img_a, img_b)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        y_true.extend(label.cpu().numpy().flatten().tolist())\n",
    "        y_scores.extend(probs.cpu().numpy().flatten().tolist())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_scores = np.array(y_scores)\n",
    "y_pred = (y_scores >= 0.5).astype(float)\n",
    "acc = (y_pred == y_true).mean()\n",
    "auc = metrics.roc_auc_score(y_true, y_scores)\n",
    "print(f'Accuracy: {acc*100:.2f}%')\n",
    "print(f'AUC: {auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c81f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualize reasoning steps (rotator-in-the-loop) ---\n",
    "# Shows the intermediate rotated states and chosen deltas\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_reasoning_steps(reasoner, img_a, img_b, steps=8, inner_steps=10):\n",
    "    reasoner.eval()\n",
    "    h_target = reasoner.encoder(img_b)\n",
    "    curr = img_a.clone()\n",
    "    h_state = reasoner.encoder(curr)\n",
    "\n",
    "    frames = [curr.clone()]\n",
    "    deltas = []\n",
    "\n",
    "    for _ in range(steps):\n",
    "        delta = reasoner.controller(h_state, h_target)\n",
    "        delta = torch.clamp(delta, -30.0, 30.0)\n",
    "        rot_emb = reasoner.to_rotator(h_state).detach()\n",
    "        curr = apply_rotation(rotator, curr, rot_emb, delta, steps=inner_steps)\n",
    "        h_state = reasoner.encoder(curr)\n",
    "        frames.append(curr.clone())\n",
    "        deltas.append(delta.detach().cpu().numpy())\n",
    "\n",
    "    return frames, deltas\n",
    "\n",
    "# Sample a pair\n",
    "key = random.choice(list(CHIRAL_SHAPES.keys()))\n",
    "base_np = draw_shape_np(key, 64)\n",
    "base = norm_tensor(base_np).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "angle = random.randint(0, 359)\n",
    "M = cv2.getRotationMatrix2D((32, 32), angle, 1.0)\n",
    "\n",
    "is_same = (random.random() > 0.5)\n",
    "if is_same:\n",
    "    target_np = cv2.warpAffine(base_np, M, (64, 64))\n",
    "    label = 'same'\n",
    "else:\n",
    "    target_np = cv2.warpAffine(cv2.flip(base_np, 1), M, (64, 64))\n",
    "    label = 'mirrored'\n",
    "\n",
    "target = norm_tensor(target_np).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "frames, deltas = run_reasoning_steps(reasoner, base, target, steps=8, inner_steps=10)\n",
    "\n",
    "cols = len(frames) + 1\n",
    "fig, axes = plt.subplots(1, cols, figsize=(3 * cols, 3))\n",
    "\n",
    "axes[0].imshow(base[0,0].cpu(), cmap='gray')\n",
    "axes[0].set_title(\"Input\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "for i in range(1, len(frames)):\n",
    "    axes[i].imshow(frames[i][0,0].cpu(), cmap='gray')\n",
    "    d = float(deltas[i-1])\n",
    "    axes[i].set_title(f\"Step {i} Î” {d:.2f} deg\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "axes[-1].imshow(target[0,0].cpu(), cmap='gray')\n",
    "axes[-1].set_title(f\"Target ({label})\")\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visual-reasoning (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
