{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e6218856",
      "metadata": {},
      "source": [
        "# Flow-Matching + PPO Rotation Alignment (Tetris)\n",
        "\n",
        "Variant A: use the **frozen flow-matching rotator** as the environment dynamics.\n",
        "The PPO agent learns to steer the rotation (action sequence) and then commit\n",
        "**match** or **mismatch** at the end for evaluation.\n",
        "\n",
        "This mirrors `notebooks/ppo_tetris.ipynb` but replaces Kornia rotation with the\n",
        "strongest FM model (`models/rotator_l1_500e_10k.pth`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "373fd4e3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/masha/Documents/visual-reasoning\n"
          ]
        }
      ],
      "source": [
        "%cd /Users/masha/Documents/visual-reasoning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f39a9785",
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "from typing import Callable, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "import timm\n",
        "import os\n",
        "\n",
        "import kornia as K\n",
        "import gymnasium as gym\n",
        "\n",
        "from stable_baselines3 import PPO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40cfb267",
      "metadata": {},
      "source": [
        "Utility helpers: device selection, seeding, state builder, and a Kornia rotation helper\n",
        "(used only to generate the synthetic source/target pairs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "511ee62f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: mps\n"
          ]
        }
      ],
      "source": [
        "def get_device() -> torch.device:\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device(\"cuda\")\n",
        "    if torch.backends.mps.is_available():\n",
        "        return torch.device(\"mps\")\n",
        "    return torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "def set_seed(seed: int = 0) -> None:\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "def build_state(source: torch.Tensor, target: torch.Tensor, angle_deg=None) -> torch.Tensor:\n",
        "    # Build state by concatenating source, target, and a constant angle channel.\n",
        "    # Handles batch expansion of target/angle if needed.\n",
        "    if source.dim() == 3:\n",
        "        source = source.unsqueeze(0)\n",
        "    if target.dim() == 3:\n",
        "        target = target.unsqueeze(0)\n",
        "    if target.shape[0] == 1 and source.shape[0] > 1:\n",
        "        target = target.expand(source.shape[0], -1, -1, -1)\n",
        "\n",
        "    state = torch.cat([source, target], dim=1)\n",
        "\n",
        "    if angle_deg is None:\n",
        "        return state\n",
        "\n",
        "    if not torch.is_tensor(angle_deg):\n",
        "        angle = torch.tensor([angle_deg], device=state.device, dtype=state.dtype)\n",
        "    else:\n",
        "        angle = angle_deg.to(device=state.device, dtype=state.dtype)\n",
        "\n",
        "    if angle.dim() == 0:\n",
        "        angle = angle.unsqueeze(0)\n",
        "    if angle.numel() == 1 and state.shape[0] > 1:\n",
        "        angle = angle.repeat(state.shape[0])\n",
        "\n",
        "    angle_norm = (angle % 360.0) / 360.0\n",
        "    angle_ch = angle_norm.view(-1, 1, 1, 1).expand(-1, 1, state.shape[2], state.shape[3])\n",
        "    return torch.cat([state, angle_ch], dim=1)\n",
        "\n",
        "\n",
        "def rotate_tensor(img: torch.Tensor, angle_deg, pad_to_diag: bool = True) -> torch.Tensor:\n",
        "    # Rotate image(s) by angle(s) in degrees using kornia.\n",
        "    # If pad_to_diag=True, pad to the diagonal size before rotating, then center-crop.\n",
        "    if img.dim() == 3:\n",
        "        img_b = img.unsqueeze(0)\n",
        "    else:\n",
        "        img_b = img\n",
        "\n",
        "    if not torch.is_tensor(angle_deg):\n",
        "        angle = torch.tensor([angle_deg], device=img_b.device, dtype=img_b.dtype)\n",
        "    else:\n",
        "        angle = angle.to(device=img_b.device, dtype=img_b.dtype)\n",
        "\n",
        "    if angle.dim() == 0:\n",
        "        angle = angle.unsqueeze(0)\n",
        "    if angle.numel() == 1 and img_b.shape[0] > 1:\n",
        "        angle = angle.repeat(img_b.shape[0])\n",
        "\n",
        "    b, c, h, w = img_b.shape\n",
        "    if pad_to_diag:\n",
        "        diag = int(math.ceil(math.sqrt(h * h + w * w)))\n",
        "        pad_h = max(0, diag - h)\n",
        "        pad_w = max(0, diag - w)\n",
        "        pad_top = pad_h // 2\n",
        "        pad_bottom = pad_h - pad_top\n",
        "        pad_left = pad_w // 2\n",
        "        pad_right = pad_w - pad_left\n",
        "        if pad_h > 0 or pad_w > 0:\n",
        "            img_p = F.pad(img_b, (pad_left, pad_right, pad_top, pad_bottom), mode=\"constant\", value=0.0)\n",
        "        else:\n",
        "            img_p = img_b\n",
        "    else:\n",
        "        img_p = img_b\n",
        "\n",
        "    rotated = K.geometry.transform.rotate(img_p, angle)\n",
        "\n",
        "    if pad_to_diag:\n",
        "        hh, ww = h, w\n",
        "        y0 = (rotated.shape[2] - hh) // 2\n",
        "        x0 = (rotated.shape[3] - ww) // 2\n",
        "        rotated = rotated[:, :, y0:y0 + hh, x0:x0 + ww]\n",
        "\n",
        "    return rotated if img.dim() == 4 else rotated.squeeze(0)\n",
        "\n",
        "\n",
        "device = get_device()\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d43f740b",
      "metadata": {},
      "source": [
        "Frozen Flow-Matching rotator (FastRotator) + DINO embedding.\n",
        "The FM model expects **1-channel inputs in [-1, 1]**. We keep it frozen and use\n",
        "it purely as a rotation dynamics model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "33b33df1",
      "metadata": {},
      "outputs": [],
      "source": [
        "DEVICE = device\n",
        "MODEL_PATH = \"models/rotator_l1_500e_10k.pth\"\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class FastRotator(nn.Module):\n",
        "    def __init__(self, backbone_dim=384, flow_dim=64):\n",
        "        super().__init__()\n",
        "        self.time_mlp = nn.Sequential(nn.Linear(1, flow_dim*4), nn.GELU(), nn.Linear(flow_dim*4, flow_dim*4))\n",
        "        self.angle_mlp = nn.Sequential(nn.Linear(1, flow_dim*4), nn.GELU(), nn.Linear(flow_dim*4, flow_dim*4))\n",
        "        self.cond_proj = nn.Linear(backbone_dim, flow_dim*4)\n",
        "\n",
        "        self.inc = DoubleConv(1, flow_dim)\n",
        "        self.down1 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(flow_dim, flow_dim*2))\n",
        "        self.down2 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(flow_dim*2, flow_dim*4))\n",
        "\n",
        "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.conv1 = DoubleConv(flow_dim*6, flow_dim*2)\n",
        "        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.conv2 = DoubleConv(flow_dim*3, flow_dim)\n",
        "\n",
        "        self.outc = nn.Conv2d(flow_dim, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x_t, t, dino_emb, target_angle_deg):\n",
        "        t_emb = self.time_mlp(t)\n",
        "        d_emb = self.cond_proj(dino_emb)\n",
        "        a_emb = self.angle_mlp(target_angle_deg / 360.0)\n",
        "        global_cond = (t_emb + d_emb + a_emb).unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "        x1 = self.inc(x_t)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x3 = x3 + global_cond\n",
        "\n",
        "        x = self.conv1(torch.cat([self.up1(x3), x2], dim=1))\n",
        "        x = self.conv2(torch.cat([self.up2(x), x1], dim=1))\n",
        "        return self.outc(x)\n",
        "\n",
        "fm_model = FastRotator().to(DEVICE)\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    raise FileNotFoundError(MODEL_PATH)\n",
        "fm_model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
        "fm_model.eval()\n",
        "for p in fm_model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "dino = timm.create_model(\"vit_small_patch16_dinov3\", pretrained=True).to(DEVICE).eval()\n",
        "for p in dino.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_dino_embedding(img_64_tensor: torch.Tensor) -> torch.Tensor:\n",
        "    # img_64_tensor: (B, 1, 64, 64) in [-1, 1]\n",
        "    img = (img_64_tensor * 0.5) + 0.5\n",
        "    img = F.interpolate(img, size=(224, 224), mode='bilinear', align_corners=False)\n",
        "    img = img.repeat(1, 3, 1, 1)\n",
        "    norm = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    img = norm(img)\n",
        "    emb = dino.forward_features(img)[:, 0, :]\n",
        "    return emb\n",
        "\n",
        "@torch.no_grad()\n",
        "def apply_rotation_fm(model, base_img, base_emb, angle_deg, steps=10):\n",
        "    # base_img: (B, 1, 64, 64) in [-1, 1]\n",
        "    model.eval()\n",
        "    dt = 1.0 / steps\n",
        "    curr = base_img.clone()\n",
        "    B = base_img.shape[0]\n",
        "    target_ang = torch.full((B, 1), float(angle_deg), device=base_img.device, dtype=base_img.dtype)\n",
        "    for i in range(steps):\n",
        "        t = torch.full((B, 1), i / steps, device=base_img.device, dtype=base_img.dtype)\n",
        "        v = model(curr, t, base_emb, target_ang)\n",
        "        curr = curr + v * dt\n",
        "    return curr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b053ddf",
      "metadata": {},
      "source": [
        "Tetris shape utilities + format conversions between\n",
        "FM space (1 channel, [-1, 1]) and PPO observation space (3 channels, [0, 1])."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ee7d9ce9",
      "metadata": {},
      "outputs": [],
      "source": [
        "CHIRAL_SHAPES = {\n",
        "    'L': [(0, -1), (0, 0), (0, 1), (1, 1)],\n",
        "    'J': [(0, -1), (0, 0), (0, 1), (-1, 1)],\n",
        "    'S': [(0, 0), (1, 0), (0, 1), (-1, 1)],\n",
        "    'Z': [(0, 0), (-1, 0), (0, 1), (1, 1)],\n",
        "    'F': [(0, 0), (0, -1), (1, -1), (-1, 0), (0, 1)],\n",
        "    'P': [(0, 0), (0, -1), (1, -1), (1, 0), (0, 1)],\n",
        "}\n",
        "\n",
        "# Smaller subset used in exhaustive_search.ipynb\n",
        "EXHAUSTIVE_SHAPE_KEYS = (\"L\", \"Z\", \"S\")\n",
        "\n",
        "\n",
        "def draw_shape_np(name: str, size: int) -> np.ndarray:\n",
        "    img = np.zeros((size, size), dtype=np.uint8)\n",
        "    center = size // 2\n",
        "    block_size = size // 8\n",
        "    for dx, dy in CHIRAL_SHAPES[name]:\n",
        "        x = center + (dx * block_size) - (block_size // 2)\n",
        "        y = center + (dy * block_size) - (block_size // 2)\n",
        "        cv2.rectangle(img, (x, y), (x + block_size, y + block_size), 255, -1)\n",
        "    return img\n",
        "\n",
        "\n",
        "_TETRIS_CACHE = {}\n",
        "\n",
        "\n",
        "def get_tetris_tensor(name: str, size: int, channels: int = 3) -> torch.Tensor:\n",
        "    key = (name, size, channels)\n",
        "    if key in _TETRIS_CACHE:\n",
        "        return _TETRIS_CACHE[key]\n",
        "    img = draw_shape_np(name, size)\n",
        "    t = torch.tensor(img).float().unsqueeze(0) / 255.0  # (1, H, W) in [0, 1]\n",
        "    if channels == 3:\n",
        "        t = t.repeat(3, 1, 1)  # (3, H, W)\n",
        "    _TETRIS_CACHE[key] = t\n",
        "    return t\n",
        "\n",
        "\n",
        "def to_fm_tensor(img: torch.Tensor) -> torch.Tensor:\n",
        "    # (C, H, W) or (B, C, H, W) in [0, 1] -> (B, 1, H, W) in [-1, 1]\n",
        "    if img.dim() == 3:\n",
        "        img = img.unsqueeze(0)\n",
        "    if img.shape[1] == 3:\n",
        "        img = img[:, :1]\n",
        "    return img * 2.0 - 1.0\n",
        "\n",
        "\n",
        "def to_obs_tensor(img: torch.Tensor) -> torch.Tensor:\n",
        "    # (B, 1, H, W) in [-1, 1] -> (B, 3, H, W) in [0, 1]\n",
        "    if img.dim() == 3:\n",
        "        img = img.unsqueeze(0)\n",
        "    img = img.clamp(-1.0, 1.0)\n",
        "    img = (img + 1.0) / 2.0\n",
        "    return img.repeat(1, 3, 1, 1)\n",
        "\n",
        "\n",
        "def make_tetris_pair_sampler(\n",
        "    image_shape: Tuple[int, int, int],\n",
        "    mirror_prob: float = 0.5,\n",
        "    angle_step: float = 5.0,\n",
        "    shape_keys=None,\n",
        ") -> Callable[[torch.device], Tuple[torch.Tensor, torch.Tensor, bool]]:\n",
        "    c, h, w = image_shape\n",
        "    keys = list(CHIRAL_SHAPES.keys()) if shape_keys is None else list(shape_keys)\n",
        "\n",
        "    def sampler(device: torch.device):\n",
        "        key = random.choice(keys)\n",
        "        target = get_tetris_tensor(key, h, channels=c)\n",
        "        is_mirrored = random.random() < mirror_prob\n",
        "        source = torch.flip(target, dims=[2]) if is_mirrored else target.clone()\n",
        "        angle = random.choice(np.arange(0.0, 360.0, angle_step))\n",
        "        source = rotate_tensor(source, angle)\n",
        "        return source, target, is_mirrored\n",
        "\n",
        "    return sampler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaff9f7c",
      "metadata": {},
      "source": [
        "Gymnasium environment with discrete rotation actions. The dynamics use the\n",
        "frozen FM model for each rotation step, while PPO learns the action policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3398983e",
      "metadata": {},
      "outputs": [],
      "source": [
        "class RotationEnvFM(gym.Env):\n",
        "    # Observation: (7, H, W) = [source(3), target(3), angle(1)] in [0, 1]\n",
        "    # Actions:\n",
        "    #   0: rotate CW  (delta = -30 deg)\n",
        "    #   1: rotate CCW (delta = +30 deg)\n",
        "    #   2: rotate CW  (delta = -15 deg)\n",
        "    #   3: rotate CCW (delta = +15 deg)\n",
        "    #   4: rotate CW  (delta = -2 deg)\n",
        "    #   5: rotate CCW (delta = +2 deg)\n",
        "    #   6: commit match (uses best error; bonus if error is tiny)\n",
        "    #   7: commit mismatch (only allowed after N steps without improvement; uses best error)\n",
        "    #   8: rotate 180 deg (flip)\n",
        "\n",
        "    metadata = {\"render_modes\": []}\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        image_shape: Tuple[int, int, int],\n",
        "        fm_model: nn.Module,\n",
        "        dino_model: nn.Module,\n",
        "        fm_steps: int = 10,\n",
        "        max_steps: int = 180,\n",
        "        max_total_rotation: float = 360.0,\n",
        "        epsilon: float = 0.03,\n",
        "        commit_bonus: float = 20.0,\n",
        "        commit_bonus_eps: Optional[float] = None,\n",
        "        mismatch_patience: int = 15,\n",
        "        improve_eps: float = 1e-6,\n",
        "        device: Optional[torch.device] = None,\n",
        "        pair_sampler: Optional[Callable[[torch.device], Tuple[torch.Tensor, torch.Tensor, bool]]] = None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.image_shape = image_shape  # (3, H, W)\n",
        "        self.fm_model = fm_model\n",
        "        self.dino_model = dino_model\n",
        "        self.fm_steps = fm_steps\n",
        "        self.max_steps = max_steps\n",
        "        self.max_total_rotation = float(max_total_rotation)\n",
        "        self.epsilon = epsilon\n",
        "        self.commit_bonus = commit_bonus\n",
        "        self.commit_bonus_eps = commit_bonus_eps if commit_bonus_eps is not None else 0.5 * epsilon\n",
        "        self.mismatch_patience = mismatch_patience\n",
        "        self.improve_eps = improve_eps\n",
        "        self.device = device or get_device()\n",
        "        self.pair_sampler = pair_sampler\n",
        "\n",
        "        _, h, w = image_shape\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            shape=(7, h, w),\n",
        "            dtype=np.float32,\n",
        "        )\n",
        "        self.action_space = gym.spaces.Discrete(9)\n",
        "\n",
        "        self.base_source_obs = None\n",
        "        self.base_source_fm = None\n",
        "        self.base_emb = None\n",
        "        self.target_obs = None\n",
        "        self.current_source_obs = None\n",
        "        self.current_source_fm = None\n",
        "        self.current_angle = 0.0\n",
        "        self.is_mirrored = False\n",
        "        self.step_count = 0\n",
        "        self.total_rotation = 0.0\n",
        "        self.prev_error = None\n",
        "        self.best_error = None\n",
        "        self.best_angle = 0.0\n",
        "        self.no_improve_steps = 0\n",
        "\n",
        "    def _set_pair(self, source: torch.Tensor, target: torch.Tensor, is_mirrored: bool) -> None:\n",
        "        self.base_source_obs = source.to(self.device).float().clamp(0, 1)\n",
        "        self.target_obs = target.to(self.device).float().clamp(0, 1)\n",
        "        if self.base_source_obs.dim() == 3:\n",
        "            self.base_source_obs = self.base_source_obs.unsqueeze(0)\n",
        "        if self.target_obs.dim() == 3:\n",
        "            self.target_obs = self.target_obs.unsqueeze(0)\n",
        "\n",
        "        self.base_source_fm = to_fm_tensor(self.base_source_obs)\n",
        "        self.base_emb = get_dino_embedding(self.base_source_fm)\n",
        "\n",
        "        self.is_mirrored = bool(is_mirrored)\n",
        "        self.current_angle = 0.0\n",
        "        self.current_source_fm = self.base_source_fm\n",
        "        self.current_source_obs = to_obs_tensor(self.current_source_fm)\n",
        "        self.step_count = 0\n",
        "        self.total_rotation = 0.0\n",
        "        self.prev_error = self._alignment_error().detach()\n",
        "        self.best_error = self.prev_error\n",
        "        self.best_angle = self.current_angle\n",
        "        self.no_improve_steps = 0\n",
        "\n",
        "    def _obs(self) -> np.ndarray:\n",
        "        state = build_state(self.current_source_obs, self.target_obs, self.current_angle)[0]\n",
        "        return state.detach().cpu().numpy().astype(np.float32)\n",
        "\n",
        "    def _alignment_error(self) -> torch.Tensor:\n",
        "        return torch.mean((self.current_source_obs - self.target_obs) ** 2)\n",
        "\n",
        "    def _update_no_improve(self, err: torch.Tensor) -> None:\n",
        "        if err < (self.prev_error - self.improve_eps):\n",
        "            self.no_improve_steps = 0\n",
        "        else:\n",
        "            self.no_improve_steps += 1\n",
        "        self.prev_error = err.detach()\n",
        "\n",
        "    def _update_best(self, err: torch.Tensor) -> None:\n",
        "        if self.best_error is None or err < self.best_error:\n",
        "            self.best_error = err.detach()\n",
        "            self.best_angle = self.current_angle\n",
        "\n",
        "    def _apply_rotation(self, delta: float) -> None:\n",
        "        self.current_angle = (self.current_angle + delta) % 360.0\n",
        "        self.total_rotation += abs(delta)\n",
        "        self.current_source_fm = apply_rotation_fm(\n",
        "            self.fm_model,\n",
        "            self.base_source_fm,\n",
        "            self.base_emb,\n",
        "            self.current_angle,\n",
        "            steps=self.fm_steps,\n",
        "        )\n",
        "        self.current_source_obs = to_obs_tensor(self.current_source_fm)\n",
        "\n",
        "    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):\n",
        "        super().reset(seed=seed)\n",
        "        options = options or {}\n",
        "\n",
        "        if \"pair\" in options:\n",
        "            source, target, is_mirrored = options[\"pair\"]\n",
        "        elif \"source\" in options and \"target\" in options:\n",
        "            source = options[\"source\"]\n",
        "            target = options[\"target\"]\n",
        "            is_mirrored = bool(options.get(\"is_mirrored\", False))\n",
        "        elif self.pair_sampler is not None:\n",
        "            source, target, is_mirrored = self.pair_sampler(self.device)\n",
        "        else:\n",
        "            raise ValueError(\"No pair provided. Pass options={pair: (...)} or set pair_sampler.\")\n",
        "\n",
        "        self._set_pair(source, target, is_mirrored)\n",
        "        info = {\"angle\": self.current_angle}\n",
        "        return self._obs(), info\n",
        "\n",
        "    def step(self, action: int):\n",
        "        terminated = False\n",
        "        reward = 0.0\n",
        "        err = self._alignment_error()\n",
        "\n",
        "        if action == 0 or action == 1:\n",
        "            delta = -30.0 if action == 0 else 30.0\n",
        "            self._apply_rotation(delta)\n",
        "            err = self._alignment_error()\n",
        "            reward = -float(err.detach())\n",
        "            self._update_best(err)\n",
        "            self._update_no_improve(err)\n",
        "        elif action == 2 or action == 3:\n",
        "            delta = -15.0 if action == 2 else 15.0\n",
        "            self._apply_rotation(delta)\n",
        "            err = self._alignment_error()\n",
        "            reward = -float(err.detach())\n",
        "            self._update_best(err)\n",
        "            self._update_no_improve(err)\n",
        "        elif action == 4 or action == 5:\n",
        "            delta = -2.0 if action == 4 else 2.0\n",
        "            self._apply_rotation(delta)\n",
        "            err = self._alignment_error()\n",
        "            reward = -float(err.detach())\n",
        "            self._update_best(err)\n",
        "            self._update_no_improve(err)\n",
        "        elif action == 8:\n",
        "            delta = 180.0\n",
        "            self._apply_rotation(delta)\n",
        "            err = self._alignment_error()\n",
        "            reward = -float(err.detach())\n",
        "            self._update_best(err)\n",
        "            self._update_no_improve(err)\n",
        "        elif action == 6:\n",
        "            best_err = float(self.best_error.detach()) if self.best_error is not None else float(err.detach())\n",
        "            if best_err < self.epsilon:\n",
        "                is_match = (not self.is_mirrored)\n",
        "                reward = 100.0 if is_match else -100.0\n",
        "                if is_match and best_err < self.commit_bonus_eps:\n",
        "                    reward += self.commit_bonus\n",
        "                terminated = True\n",
        "            else:\n",
        "                reward = -float(err.detach())\n",
        "                self._update_no_improve(err)\n",
        "        elif action == 7:\n",
        "            if self.no_improve_steps >= self.mismatch_patience:\n",
        "                best_err = float(self.best_error.detach()) if self.best_error is not None else float(err.detach())\n",
        "                is_mismatch = self.is_mirrored and (best_err >= self.epsilon)\n",
        "                reward = 100.0 if is_mismatch else -100.0\n",
        "                terminated = True\n",
        "            else:\n",
        "                reward = -float(err.detach())\n",
        "                self._update_no_improve(err)\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid action: {action}\")\n",
        "\n",
        "        self.step_count += 1\n",
        "        truncated = (self.step_count >= self.max_steps) and (not terminated)\n",
        "        if self.total_rotation >= self.max_total_rotation and not terminated:\n",
        "            truncated = True\n",
        "\n",
        "        info = {\n",
        "            \"angle\": self.current_angle,\n",
        "            \"error\": float(err.detach().cpu()),\n",
        "            \"best_error\": float(self.best_error.detach().cpu()) if self.best_error is not None else float(err.detach().cpu()),\n",
        "            \"best_angle\": float(self.best_angle),\n",
        "            \"is_mirrored\": self.is_mirrored,\n",
        "            \"no_improve_steps\": self.no_improve_steps,\n",
        "            \"total_rotation\": float(self.total_rotation),\n",
        "        }\n",
        "        return self._obs(), float(reward), terminated, truncated, info"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4025661d",
      "metadata": {},
      "source": [
        "Train PPO using the FM-driven environment (variant A)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dc68728",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Logging to logs/ppo_tetris_fm\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 14       |\n",
            "|    ep_rew_mean     | 0.617    |\n",
            "| time/              |          |\n",
            "|    fps             | 48       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 41       |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 11.9        |\n",
            "|    ep_rew_mean          | 0.693       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 45          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 89          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016714994 |\n",
            "|    clip_fraction        | 0.216       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.18       |\n",
            "|    explained_variance   | 0.00252     |\n",
            "|    learning_rate        | 0.0002      |\n",
            "|    loss                 | 11.5        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0128     |\n",
            "|    value_loss           | 96.1        |\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "set_seed(0)\n",
        "\n",
        "H, W = 64, 64\n",
        "image_shape = (3, H, W)\n",
        "\n",
        "# Use the exhaustive-search subset by default; set to None to use all shapes\n",
        "shape_keys = EXHAUSTIVE_SHAPE_KEYS\n",
        "\n",
        "sampler = make_tetris_pair_sampler(\n",
        "    image_shape=image_shape,\n",
        "    mirror_prob=0.5,\n",
        "    angle_step=5.0,\n",
        "    shape_keys=shape_keys,\n",
        ")\n",
        "\n",
        "env = RotationEnvFM(\n",
        "    image_shape=image_shape,\n",
        "    fm_model=fm_model,\n",
        "    dino_model=dino,\n",
        "    fm_steps=10,\n",
        "    max_steps=180,\n",
        "    epsilon=0.03,\n",
        "    device=device,\n",
        "    pair_sampler=sampler,\n",
        ")\n",
        "\n",
        "model = PPO(\n",
        "    \"CnnPolicy\",\n",
        "    env,\n",
        "    verbose=1,\n",
        "    device=\"auto\",\n",
        "    learning_rate=2e-4,\n",
        "    policy_kwargs={\"normalize_images\": False},\n",
        ")\n",
        "\n",
        "from stable_baselines3.common.logger import configure\n",
        "log_dir = \"logs/ppo_tetris_fm\"\n",
        "logger = configure(log_dir, [\"stdout\", \"csv\"])\n",
        "model.set_logger(logger)\n",
        "\n",
        "# Train (increase total_timesteps for better performance)\n",
        "model.learn(total_timesteps=50_000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01586066",
      "metadata": {},
      "source": [
        "Evaluate match/mismatch success rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2899a3c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "eval_env = RotationEnvFM(\n",
        "    image_shape=image_shape,\n",
        "    fm_model=fm_model,\n",
        "    dino_model=dino,\n",
        "    fm_steps=10,\n",
        "    max_steps=180,\n",
        "    epsilon=0.03,\n",
        "    device=device,\n",
        "    pair_sampler=sampler,\n",
        ")\n",
        "\n",
        "n_eval_episodes = 30\n",
        "success = 0\n",
        "rewards = []\n",
        "\n",
        "for _ in range(n_eval_episodes):\n",
        "    obs, _ = eval_env.reset()\n",
        "    terminated = False\n",
        "    truncated = False\n",
        "    ep_reward = 0.0\n",
        "    last_reward = 0.0\n",
        "\n",
        "    while not (terminated or truncated):\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, reward, terminated, truncated, info = eval_env.step(int(action))\n",
        "        ep_reward += float(reward)\n",
        "        last_reward = float(reward)\n",
        "\n",
        "    rewards.append(ep_reward)\n",
        "    if terminated and last_reward > 0:\n",
        "        success += 1\n",
        "\n",
        "print(f\"Mean episode reward: {np.mean(rewards):.2f}\")\n",
        "print(f\"Success rate: {success / n_eval_episodes:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdc542ef",
      "metadata": {},
      "source": [
        "Diagnostic: MSE at commit time for correct vs incorrect decisions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f16b57d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if 'eval_env' not in globals():\n",
        "    eval_env = RotationEnvFM(\n",
        "        image_shape=image_shape,\n",
        "        fm_model=fm_model,\n",
        "        dino_model=dino,\n",
        "        fm_steps=10,\n",
        "        max_steps=180,\n",
        "        epsilon=0.03,\n",
        "        device=device,\n",
        "        pair_sampler=sampler,\n",
        "    )\n",
        "\n",
        "n_diag = 50\n",
        "errs_correct = []\n",
        "errs_wrong = []\n",
        "\n",
        "for _ in range(n_diag):\n",
        "    obs, _ = eval_env.reset()\n",
        "    terminated = False\n",
        "    truncated = False\n",
        "    last_reward = 0.0\n",
        "    last_info = {}\n",
        "\n",
        "    while not (terminated or truncated):\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, reward, terminated, truncated, info = eval_env.step(int(action))\n",
        "        last_reward = float(reward)\n",
        "        last_info = info\n",
        "\n",
        "    if terminated:\n",
        "        best_err = last_info.get('best_error', last_info.get('error', None))\n",
        "        if best_err is not None:\n",
        "            if last_reward > 0:\n",
        "                errs_correct.append(best_err)\n",
        "            else:\n",
        "                errs_wrong.append(best_err)\n",
        "\n",
        "plt.figure(figsize=(4, 3))\n",
        "if errs_correct:\n",
        "    plt.hist(errs_correct, bins=20, alpha=0.6, label='correct')\n",
        "if errs_wrong:\n",
        "    plt.hist(errs_wrong, bins=20, alpha=0.6, label='incorrect')\n",
        "plt.axvline(eval_env.epsilon, color='k', linestyle='--', label='epsilon')\n",
        "plt.xlabel('Best MSE at commit')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Commit MSE (correct vs incorrect)')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c29c537",
      "metadata": {},
      "source": [
        "Plot PPO losses from the CSV logger."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c748488b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "\n",
        "log_path = os.path.join(log_dir, \"progress.csv\")\n",
        "if not os.path.exists(log_path):\n",
        "    print(f\"No progress.csv found at {log_path}. Did training run?\")\n",
        "else:\n",
        "    with open(log_path, \"r\", newline=\"\") as f:\n",
        "        rows = list(csv.DictReader(f))\n",
        "\n",
        "    def get_series(key: str):\n",
        "        vals = []\n",
        "        for r in rows:\n",
        "            v = r.get(key, \"\")\n",
        "            if v != \"\" and v is not None:\n",
        "                vals.append(float(v))\n",
        "        return vals\n",
        "\n",
        "    policy_loss = get_series(\"train/policy_gradient_loss\")\n",
        "    value_loss = get_series(\"train/value_loss\")\n",
        "    entropy_loss = get_series(\"train/entropy_loss\")\n",
        "    total_loss = get_series(\"train/loss\")\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
        "    if policy_loss:\n",
        "        axes[0].plot(policy_loss, label=\"policy\")\n",
        "    if entropy_loss:\n",
        "        axes[0].plot(entropy_loss, label=\"entropy\")\n",
        "    axes[0].set_title(\"Policy/Entropy\")\n",
        "    axes[0].set_xlabel(\"Update\")\n",
        "    axes[0].legend()\n",
        "\n",
        "    if value_loss:\n",
        "        axes[1].plot(value_loss, label=\"value\")\n",
        "    if total_loss:\n",
        "        axes[1].plot(total_loss, label=\"total\")\n",
        "    axes[1].set_title(\"Value/Total\")\n",
        "    axes[1].set_xlabel(\"Update\")\n",
        "    axes[1].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abfd9ae5",
      "metadata": {},
      "source": [
        "Generate a rollout GIF to visualize the FM-driven rotation trajectory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd652d23",
      "metadata": {},
      "outputs": [],
      "source": [
        "import imageio.v2 as imageio\n",
        "import time\n",
        "from IPython.display import Image, display\n",
        "\n",
        "\n",
        "def render_pair_frame(source: torch.Tensor, target: torch.Tensor) -> np.ndarray:\n",
        "    # Return a side-by-side frame (H, 2W, 3) as uint8.\n",
        "    src = (source.clamp(0, 1).permute(1, 2, 0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
        "    tgt = (target.clamp(0, 1).permute(1, 2, 0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
        "    return np.concatenate([src, tgt], axis=1)\n",
        "\n",
        "\n",
        "def rollout_and_save_gif(\n",
        "    env: RotationEnvFM,\n",
        "    model: PPO,\n",
        "    out_path: str = \"gifs/rotation_ppo_tetris_fm_episode.gif\",\n",
        "    seed: Optional[int] = None,\n",
        "    max_steps: int = 360,\n",
        "    fps: int = 8,\n",
        "):\n",
        "    if seed is not None:\n",
        "        set_seed(seed)\n",
        "    obs, _ = env.reset()\n",
        "    frames = []\n",
        "\n",
        "    for _ in range(max_steps):\n",
        "        frames.append(render_pair_frame(env.current_source_obs[0], env.target_obs[0]))\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, _, terminated, truncated, _ = env.step(int(action))\n",
        "        if terminated or truncated:\n",
        "            frames.append(render_pair_frame(env.current_source_obs[0], env.target_obs[0]))\n",
        "            break\n",
        "\n",
        "    imageio.mimsave(out_path, frames, fps=fps)\n",
        "    return out_path\n",
        "\n",
        "\n",
        "gif_env = RotationEnvFM(\n",
        "    image_shape=image_shape,\n",
        "    fm_model=fm_model,\n",
        "    dino_model=dino,\n",
        "    fm_steps=10,\n",
        "    max_steps=180,\n",
        "    epsilon=0.03,\n",
        "    device=device,\n",
        "    pair_sampler=sampler,\n",
        ")\n",
        "\n",
        "gif_paths = []\n",
        "base_seed = int(time.time()) % 1000000\n",
        "for i in range(3):\n",
        "    out_path = f\"gifs/rotation_ppo_tetris_fm_episode_sample_{i+1}.gif\"\n",
        "    gif_paths.append(rollout_and_save_gif(gif_env, model, out_path=out_path, seed=base_seed + i))\n",
        "\n",
        "for p in gif_paths:\n",
        "    display(Image(filename=p))\n",
        "\n",
        "gif_paths"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "visual-reasoning (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
