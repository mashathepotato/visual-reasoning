{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb5f974f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/masha/Documents/visual-reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/masha/Documents/visual-reasoning/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/masha/Documents/visual-reasoning\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timm\n",
    "import kornia.geometry.transform as K # Crucial for 2D rotation heuristic\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-4\n",
    "EPOCHS = 30\n",
    "SUBDIVISION_CAP = 4  # Split the rotation path into 4 segments\n",
    "\n",
    "# DINOv3 Constants\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d1a7814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 153\n"
     ]
    }
   ],
   "source": [
    "train_raw = np.load('./data/train_pairs.npy', allow_pickle=True)\n",
    "test_raw = np.load('./data/test_balanced.npy', allow_pickle=True)\n",
    "\n",
    "def prepare_data(raw_list, is_train=False):\n",
    "    x0 = torch.tensor(np.stack([d['x0'] for d in raw_list])).float()\n",
    "    x1 = torch.tensor(np.stack([d['x1'] for d in raw_list])).float()\n",
    "    \n",
    "    if x0.max() > 1.0:\n",
    "        x0 = x0 / 255.0\n",
    "        x1 = x1 / 255.0\n",
    "        \n",
    "    if x0.shape[1] == 1:\n",
    "        x0 = x0.repeat(1, 3, 1, 1)\n",
    "        x1 = x1.repeat(1, 3, 1, 1)\n",
    "    \n",
    "    normalize = transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "    x0 = normalize(x0)\n",
    "    x1 = normalize(x1)\n",
    "    \n",
    "    if is_train:\n",
    "        y = torch.ones(len(raw_list))\n",
    "    else:\n",
    "        y = torch.tensor([1.0 if d.get('label') == 'same' else 0.0 for d in raw_list])\n",
    "        \n",
    "    return x0, x1, y\n",
    "\n",
    "train_x0, train_x1, train_y = prepare_data(train_raw, is_train=True)\n",
    "test_x0, test_x1, test_y = prepare_data(test_raw, is_train=False)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_x0, train_x1, train_y), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader  = DataLoader(TensorDataset(test_x0, test_x1, test_y), batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Train Size: {len(train_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d34850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visual-reasoning (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
