{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb5f974f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/masha/Documents/visual-reasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/masha/Documents/visual-reasoning/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/masha/Documents/visual-reasoning\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timm\n",
    "import kornia.geometry.transform as K # Crucial for 2D rotation heuristic\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-4\n",
    "EPOCHS = 30\n",
    "SUBDIVISION_CAP = 4  # Split the rotation path into 4 segments\n",
    "\n",
    "# DINOv3 Constants\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d1a7814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 153\n"
     ]
    }
   ],
   "source": [
    "train_raw = np.load('./data/train_pairs.npy', allow_pickle=True)\n",
    "test_raw = np.load('./data/test_balanced.npy', allow_pickle=True)\n",
    "\n",
    "def prepare_data(raw_list, is_train=False):\n",
    "    x0 = torch.tensor(np.stack([d['x0'] for d in raw_list])).float()\n",
    "    x1 = torch.tensor(np.stack([d['x1'] for d in raw_list])).float()\n",
    "    \n",
    "    if x0.max() > 1.0:\n",
    "        x0 = x0 / 255.0\n",
    "        x1 = x1 / 255.0\n",
    "        \n",
    "    if x0.shape[1] == 1:\n",
    "        x0 = x0.repeat(1, 3, 1, 1)\n",
    "        x1 = x1.repeat(1, 3, 1, 1)\n",
    "    \n",
    "    normalize = transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "    x0 = normalize(x0)\n",
    "    x1 = normalize(x1)\n",
    "    \n",
    "    if is_train:\n",
    "        y = torch.ones(len(raw_list))\n",
    "    else:\n",
    "        y = torch.tensor([1.0 if d.get('label') == 'same' else 0.0 for d in raw_list])\n",
    "        \n",
    "    return x0, x1, y\n",
    "\n",
    "train_x0, train_x1, train_y = prepare_data(train_raw, is_train=True)\n",
    "test_x0, test_x1, test_y = prepare_data(test_raw, is_train=False)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_x0, train_x1, train_y), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader  = DataLoader(TensorDataset(test_x0, test_x1, test_y), batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Train Size: {len(train_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d34850",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.MaxPool2d(2), DoubleConv(in_ch, out_ch))\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv = DoubleConv(in_ch, out_ch)\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class FlowReasoningModel(nn.Module):\n",
    "    def __init__(self, backbone, backbone_dim=384, flow_dim=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Frozen Backbone\n",
    "        self.backbone = backbone\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Time Embedding\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(1, flow_dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(flow_dim * 4, flow_dim * 4)\n",
    "        )\n",
    "\n",
    "        # Encoder (64x64)\n",
    "        self.inc = DoubleConv(3, flow_dim)            \n",
    "        self.down1 = Down(flow_dim, flow_dim * 2)     \n",
    "        self.down2 = Down(flow_dim * 2, flow_dim * 4) # Bottleneck\n",
    "        \n",
    "        # Projection\n",
    "        self.cond_proj = nn.Linear(backbone_dim, flow_dim * 4)\n",
    "\n",
    "        # Decoder\n",
    "        self.up1 = Up(flow_dim * 6, flow_dim * 2) \n",
    "        self.up2 = Up(flow_dim * 3, flow_dim)\n",
    "        self.outc = nn.Conv2d(flow_dim, 3, kernel_size=1)\n",
    "\n",
    "    def forward(self, x_t, t, x0_clean):\n",
    "        with torch.no_grad():\n",
    "            x0_high = F.interpolate(x0_clean, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "            feats = self.backbone.forward_features(x0_high)\n",
    "            cls_token = feats[:, 0, :] \n",
    "\n",
    "        t_emb = self.time_mlp(t)             \n",
    "        cond = self.cond_proj(cls_token)     \n",
    "        global_cond = (t_emb + cond).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        x1 = self.inc(x_t)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        \n",
    "        # Inject Reasoning\n",
    "        x3 = x3 + global_cond\n",
    "        \n",
    "        x = self.up1(x3, x2)\n",
    "        x = self.up2(x, x1)\n",
    "        return self.outc(x)\n",
    "\n",
    "dinov3 = timm.create_model(\"vit_small_patch16_dinov3\", pretrained=True).to(DEVICE).eval()\n",
    "model = FlowReasoningModel(backbone=dinov3).to(DEVICE)\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6199523d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visual-reasoning (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
