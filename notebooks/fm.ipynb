{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5563326b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/masha/Documents\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import marimo as mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ac53203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Shape: torch.Size([32, 3, 64, 64])\n",
      "Label Shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "train_raw = np.load('./data/train_pairs.npy', allow_pickle=True)\n",
    "test_raw = np.load('./data/test_balanced.npy', allow_pickle=True)\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "def prepare_data(raw_list, is_train=False):\n",
    "    # Stack all images into one tensor (N, 1, 64, 64)\n",
    "    x0 = torch.tensor(np.stack([d['x0'] for d in raw_list])).float()\n",
    "    x1 = torch.tensor(np.stack([d['x1'] for d in raw_list])).float()\n",
    "    \n",
    "    # DINOv3 requires 3-channel input even for grayscale data\n",
    "    x0 = x0.repeat(1, 3, 1, 1)\n",
    "    x1 = x1.repeat(1, 3, 1, 1)\n",
    "    \n",
    "    # Normalize with respect to ImageNet for DINOv3\n",
    "    x0 = (x0 + 1) * 0.5 \n",
    "    x1 = (x1 + 1) * 0.5\n",
    "    # print(x0, x1)\n",
    "    \n",
    "    # Apply ImageNet Normalization\n",
    "    normalize = transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "    x0 = normalize(x0)\n",
    "    x1 = normalize(x1)\n",
    "    \n",
    "    if is_train:\n",
    "        y = torch.ones(len(raw_list))\n",
    "    else:\n",
    "        y = torch.tensor([1.0 if d.get('label') == 'same' else 0.0 for d in raw_list])\n",
    "        \n",
    "    return x0, x1, y\n",
    "\n",
    "train_x0, train_x1, train_y = prepare_data(train_raw, is_train=True)\n",
    "test_x0, test_x1, test_y = prepare_data(test_raw, is_train=False)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_x0, train_x1, train_y), batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(TensorDataset(test_x0, test_x1, test_y), batch_size=32)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"Batch Shape: {batch[0].shape}\")\n",
    "print(f\"Label Shape: {batch[2].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f05217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.MaxPool2d(2), DoubleConv(in_ch, out_ch))\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv = DoubleConv(in_ch, out_ch)\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e36acdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowReasoningModel(nn.Module):\n",
    "    def __init__(self, backbone, backbone_dim=384, flow_dim=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone = backbone\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Time Embedding (t -> feature)\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(1, flow_dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(flow_dim * 4, flow_dim * 4)\n",
    "        )\n",
    "\n",
    "        # FLow UNet\n",
    "        self.inc = DoubleConv(3, flow_dim)\n",
    "        self.down1 = Down(flow_dim, flow_dim * 2)\n",
    "        self.down2 = Down(flow_dim * 2, flow_dim * 4) # Bottleneck (256 ch)\n",
    "        \n",
    "        # Project DINO features to Bottleneck size\n",
    "        self.cond_proj = nn.Linear(backbone_dim, flow_dim * 4)\n",
    "\n",
    "        self.up1 = Up(flow_dim * 8, flow_dim * 2)\n",
    "        self.up2 = Up(flow_dim * 4, flow_dim)\n",
    "        self.outc = nn.Conv2d(flow_dim, 3, kernel_size=1)\n",
    "\n",
    "    def forward(self, x_t, t, x0_clean):\n",
    "        with torch.no_grad():\n",
    "            # Extract features (adjust key based on specific DINOv3 output)\n",
    "            feats = self.backbone.forward_features(x0_clean)\n",
    "            cls_token = feats['x_norm_clstoken'] # Standard DINO output key\n",
    "\n",
    "        # B. Embed Time & Condition\n",
    "        t_emb = self.time_mlp(t)                 # (B, 256)\n",
    "        cond = self.cond_proj(cls_token)         # (B, 256)\n",
    "        global_cond = (t_emb + cond).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        x1 = self.inc(x_t)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        \n",
    "        # Inject Reasoning (Time + DINO)\n",
    "        x3 = x3 + global_cond\n",
    "        \n",
    "        x = self.up1(x3, x2)\n",
    "        x = self.up2(x, x1)\n",
    "        return self.outc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59fa15c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/masha/.cache/torch/hub/facebookresearch_dinov3_main\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'termcolor'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m dinov3 = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfacebookresearch/dinov3\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdinov3_vits14\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m dinov3.to(device)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# backbone_dim=384 for ViT-Small, 768 for ViT-Base\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/visual-reasoning/.venv/lib/python3.12/site-packages/torch/hub.py:652\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[39m\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source == \u001b[33m\"\u001b[39m\u001b[33mgithub\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    643\u001b[39m     repo_or_dir = _get_cache_or_reload(\n\u001b[32m    644\u001b[39m         repo_or_dir,\n\u001b[32m    645\u001b[39m         force_reload,\n\u001b[32m   (...)\u001b[39m\u001b[32m    649\u001b[39m         skip_validation=skip_validation,\n\u001b[32m    650\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m652\u001b[39m model = \u001b[43m_load_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_or_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/visual-reasoning/.venv/lib/python3.12/site-packages/torch/hub.py:682\u001b[39m, in \u001b[36m_load_local\u001b[39m\u001b[34m(hubconf_dir, model, *args, **kwargs)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _add_to_sys_path(hubconf_dir):\n\u001b[32m    681\u001b[39m     hubconf_path = os.path.join(hubconf_dir, MODULE_HUBCONF)\n\u001b[32m--> \u001b[39m\u001b[32m682\u001b[39m     hub_module = \u001b[43m_import_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODULE_HUBCONF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhubconf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    684\u001b[39m     entry = _load_entry_from_hubconf(hub_module, model)\n\u001b[32m    685\u001b[39m     model = entry(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/visual-reasoning/.venv/lib/python3.12/site-packages/torch/hub.py:115\u001b[39m, in \u001b[36m_import_module\u001b[39m\u001b[34m(name, path)\u001b[39m\n\u001b[32m    113\u001b[39m module = importlib.util.module_from_spec(spec)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec.loader, Loader)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m \u001b[43mspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:999\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/torch/hub/facebookresearch_dinov3_main/hubconf.py:22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdinov3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhub\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdetectors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dinov3_vit7b16_de\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdinov3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhub\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdinotxt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dinov3_vitl16_dinotxt_tet1280d20h24l\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdinov3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhub\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msegmentors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dinov3_vit7b16_ms\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdinov3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhub\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdepthers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dinov3_vit7b16_dd\n\u001b[32m     26\u001b[39m dependencies = [\u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/torch/hub/facebookresearch_dinov3_main/dinov3/hub/segmentors.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdinov3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meval\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msegmentation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_segmentation_decoder\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackbones\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     13\u001b[39m     dinov3_vit7b16,\n\u001b[32m     14\u001b[39m     dinov3_vitl16,\n\u001b[32m     15\u001b[39m     Weights \u001b[38;5;28;01mas\u001b[39;00m BackboneWeights,\n\u001b[32m     16\u001b[39m     convert_path_or_url_to_url,\n\u001b[32m     17\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DINOV3_BASE_URL\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/torch/hub/facebookresearch_dinov3_main/dinov3/eval/segmentation/models/__init__.py:14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdinov3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meval\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msegmentation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mheads\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_head\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearHead\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdinov3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meval\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msegmentation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mheads\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmask2former_head\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Mask2FormerHead\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdinov3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meval\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelWithIntermediateLayers\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mBackboneLayersSet\u001b[39;00m(Enum):\n\u001b[32m     18\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[33;03m    Set of intermediate layers to take from the backbone.\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/torch/hub/facebookresearch_dinov3_main/dinov3/eval/utils.py:20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdinov3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatasetWithEnumeratedTargets, SamplerType, make_data_loader\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdinov3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meval\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maccumulators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NoOpAccumulator, ResultsAccumulator\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdinov3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MetricLogger\n\u001b[32m     22\u001b[39m logger = logging.getLogger(\u001b[33m\"\u001b[39m\u001b[33mdinov3\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mLossType\u001b[39;00m(Enum):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/torch/hub/facebookresearch_dinov3_main/dinov3/logging/__init__.py:12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtermcolor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m colored\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdinov3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TorchDistributedEnvironment\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdinov3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogging\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhelpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MetricLogger, SmoothedValue\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'termcolor'"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dinov3 = torch.hub.load('facebookresearch/dinov3', 'dinov3_vits14')\n",
    "dinov3.to(device)\n",
    "\n",
    "# backbone_dim=384 for ViT-Small, 768 for ViT-Base\n",
    "model = FlowReasoningModel(backbone=dinov3, backbone_dim=384)\n",
    "model.to(device)\n",
    "\n",
    "# 3. Sanity Check\n",
    "print(f\"Model Parameters (Trainable): {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "dummy_in = torch.randn(2, 3, 64, 64).to(device)\n",
    "dummy_t = torch.rand(2, 1).to(device)\n",
    "out = model(dummy_in, dummy_t, dummy_in)\n",
    "print(f\"Output Shape: {out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2732ca10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visual-reasoning (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
