{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67bb907d",
   "metadata": {},
   "source": [
    "# PPO Rotation Alignment Agent (Kornia + PyTorch)\n",
    "\n",
    "This notebook trains a minimal PPO agent on the same synthetic rotation/mirror dataset used in `dqn.ipynb`.\n",
    "We use Stable-Baselines3's baseline PPO implementation and keep everything intentionally barebones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8dee0bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from typing import Callable, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import kornia as K\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3 import PPO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6aafb33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "def get_device() -> torch.device:\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 0) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def build_state(source: torch.Tensor, target: torch.Tensor, angle_deg=None) -> torch.Tensor:\n",
    "    # Build state by concatenating source, target, and a constant angle channel.\n",
    "    # Handles batch expansion of target/angle if needed.\n",
    "    if source.dim() == 3:\n",
    "        source = source.unsqueeze(0)\n",
    "    if target.dim() == 3:\n",
    "        target = target.unsqueeze(0)\n",
    "    if target.shape[0] == 1 and source.shape[0] > 1:\n",
    "        target = target.expand(source.shape[0], -1, -1, -1)\n",
    "\n",
    "    state = torch.cat([source, target], dim=1)\n",
    "\n",
    "    if angle_deg is None:\n",
    "        return state\n",
    "\n",
    "    if not torch.is_tensor(angle_deg):\n",
    "        angle = torch.tensor([angle_deg], device=state.device, dtype=state.dtype)\n",
    "    else:\n",
    "        angle = angle_deg.to(device=state.device, dtype=state.dtype)\n",
    "\n",
    "    if angle.dim() == 0:\n",
    "        angle = angle.unsqueeze(0)\n",
    "    if angle.numel() == 1 and state.shape[0] > 1:\n",
    "        angle = angle.repeat(state.shape[0])\n",
    "\n",
    "    angle_norm = (angle % 360.0) / 360.0\n",
    "    angle_ch = angle_norm.view(-1, 1, 1, 1).expand(-1, 1, state.shape[2], state.shape[3])\n",
    "    return torch.cat([state, angle_ch], dim=1)\n",
    "\n",
    "\n",
    "def rotate_tensor(img: torch.Tensor, angle_deg, pad_to_diag: bool = True) -> torch.Tensor:\n",
    "    # Rotate image(s) by angle(s) in degrees using kornia.\n",
    "    # If pad_to_diag=True, pad to the diagonal size before rotating, then center-crop.\n",
    "    if img.dim() == 3:\n",
    "        img_b = img.unsqueeze(0)\n",
    "    else:\n",
    "        img_b = img\n",
    "\n",
    "    if not torch.is_tensor(angle_deg):\n",
    "        angle = torch.tensor([angle_deg], device=img_b.device, dtype=img_b.dtype)\n",
    "    else:\n",
    "        angle = angle_deg.to(device=img_b.device, dtype=img_b.dtype)\n",
    "\n",
    "    if angle.dim() == 0:\n",
    "        angle = angle.unsqueeze(0)\n",
    "    if angle.numel() == 1 and img_b.shape[0] > 1:\n",
    "        angle = angle.repeat(img_b.shape[0])\n",
    "\n",
    "    b, c, h, w = img_b.shape\n",
    "    if pad_to_diag:\n",
    "        diag = int(math.ceil(math.sqrt(h * h + w * w)))\n",
    "        pad_h = max(0, diag - h)\n",
    "        pad_w = max(0, diag - w)\n",
    "        pad_top = pad_h // 2\n",
    "        pad_bottom = pad_h - pad_top\n",
    "        pad_left = pad_w // 2\n",
    "        pad_right = pad_w - pad_left\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            img_p = F.pad(img_b, (pad_left, pad_right, pad_top, pad_bottom), mode=\"constant\", value=0.0)\n",
    "        else:\n",
    "            img_p = img_b\n",
    "    else:\n",
    "        img_p = img_b\n",
    "\n",
    "    rotated = K.geometry.transform.rotate(img_p, angle)\n",
    "\n",
    "    if pad_to_diag:\n",
    "        hh, ww = h, w\n",
    "        y0 = (rotated.shape[2] - hh) // 2\n",
    "        x0 = (rotated.shape[3] - ww) // 2\n",
    "        rotated = rotated[:, :, y0:y0 + hh, x0:x0 + ww]\n",
    "\n",
    "    return rotated if img.dim() == 4 else rotated.squeeze(0)\n",
    "\n",
    "\n",
    "device = get_device()\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb87576",
   "metadata": {},
   "source": [
    "Next, we recreate the **same synthetic dataset** as the DQN notebook: colored rectangles on a black background.\n",
    "The source image is either a rotated copy of the target (match) or a mirrored + rotated version (mismatch).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a123738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_target_image(h: int, w: int, num_shapes: int = 4) -> torch.Tensor:\n",
    "    img = torch.zeros(3, h, w)\n",
    "    for _ in range(num_shapes):\n",
    "        color = torch.rand(3, 1, 1)\n",
    "        y0 = random.randint(0, h - 8)\n",
    "        x0 = random.randint(0, w - 8)\n",
    "        y1 = min(h, y0 + random.randint(6, h // 2))\n",
    "        x1 = min(w, x0 + random.randint(6, w // 2))\n",
    "        img[:, y0:y1, x0:x1] = color\n",
    "    return img\n",
    "\n",
    "\n",
    "def make_pair_sampler(\n",
    "    image_shape: Tuple[int, int, int],\n",
    "    mirror_prob: float = 0.5,\n",
    "    angle_step: float = 5.0,\n",
    ") -> Callable[[torch.device], Tuple[torch.Tensor, torch.Tensor, bool]]:\n",
    "    _, h, w = image_shape\n",
    "\n",
    "    def sampler(device: torch.device):\n",
    "        target = random_target_image(h, w)\n",
    "        is_mirrored = random.random() < mirror_prob\n",
    "        source = torch.flip(target, dims=[2]) if is_mirrored else target.clone()\n",
    "        angle = random.choice(np.arange(0.0, 360.0, angle_step))\n",
    "        source = rotate_tensor(source, angle)\n",
    "        return source, target, is_mirrored\n",
    "\n",
    "    return sampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4766bd3",
   "metadata": {},
   "source": [
    "Now we define the Gymnasium environment. It's the same action space and reward logic as in `dqn.ipynb`,\n",
    "just adapted to return **NumPy observations** so Stable-Baselines3 can consume them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73f70588",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotationEnv(gym.Env):\n",
    "    # Observation: (7, H, W) = [source(3), target(3), angle(1)] in [0, 1]\n",
    "    # Actions:\n",
    "    #   0: rotate CW  (delta = -10 deg)\n",
    "    #   1: rotate CCW (delta = +10 deg)\n",
    "    #   2: rotate CW  (delta = -5 deg)\n",
    "    #   3: rotate CCW (delta = +5 deg)\n",
    "    #   4: rotate CW  (delta = -1 deg)\n",
    "    #   5: rotate CCW (delta = +1 deg)\n",
    "    #   6: commit match (only allowed if error < epsilon)\n",
    "    #   7: commit mismatch (only allowed after N steps without improvement)\n",
    "\n",
    "    metadata = {\"render_modes\": []}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_shape: Tuple[int, int, int],\n",
    "        max_steps: int = 180,\n",
    "        epsilon: float = 0.03,\n",
    "        mismatch_patience: int = 20,\n",
    "        improve_eps: float = 1e-6,\n",
    "        device: Optional[torch.device] = None,\n",
    "        pair_sampler: Optional[Callable[[torch.device], Tuple[torch.Tensor, torch.Tensor, bool]]] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.image_shape = image_shape  # (3, H, W)\n",
    "        self.max_steps = max_steps\n",
    "        self.epsilon = epsilon\n",
    "        self.mismatch_patience = mismatch_patience\n",
    "        self.improve_eps = improve_eps\n",
    "        self.device = device or get_device()\n",
    "        self.pair_sampler = pair_sampler\n",
    "\n",
    "        _, h, w = image_shape\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0.0,\n",
    "            high=1.0,\n",
    "            shape=(7, h, w),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        self.action_space = gym.spaces.Discrete(8)\n",
    "\n",
    "        self.base_source = None\n",
    "        self.target = None\n",
    "        self.current_source = None\n",
    "        self.current_angle = 0.0\n",
    "        self.is_mirrored = False\n",
    "        self.step_count = 0\n",
    "        self.prev_error = None\n",
    "        self.no_improve_steps = 0\n",
    "\n",
    "    def _set_pair(self, source: torch.Tensor, target: torch.Tensor, is_mirrored: bool) -> None:\n",
    "        self.base_source = source.to(self.device).float().clamp(0, 1)\n",
    "        self.target = target.to(self.device).float().clamp(0, 1)\n",
    "        self.is_mirrored = bool(is_mirrored)\n",
    "        self.current_angle = 0.0\n",
    "        self.current_source = self.base_source\n",
    "        self.step_count = 0\n",
    "        self.prev_error = self._alignment_error().detach()\n",
    "        self.no_improve_steps = 0\n",
    "\n",
    "    def _obs(self) -> np.ndarray:\n",
    "        state = build_state(self.current_source, self.target, self.current_angle)[0]\n",
    "        return state.detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "    def _alignment_error(self) -> torch.Tensor:\n",
    "        return torch.mean((self.current_source - self.target) ** 2)\n",
    "\n",
    "    def _update_no_improve(self, err: torch.Tensor) -> None:\n",
    "        if err < (self.prev_error - self.improve_eps):\n",
    "            self.no_improve_steps = 0\n",
    "        else:\n",
    "            self.no_improve_steps += 1\n",
    "        self.prev_error = err.detach()\n",
    "\n",
    "    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):\n",
    "        super().reset(seed=seed)\n",
    "        options = options or {}\n",
    "\n",
    "        if \"pair\" in options:\n",
    "            source, target, is_mirrored = options[\"pair\"]\n",
    "        elif \"source\" in options and \"target\" in options:\n",
    "            source = options[\"source\"]\n",
    "            target = options[\"target\"]\n",
    "            is_mirrored = bool(options.get(\"is_mirrored\", False))\n",
    "        elif self.pair_sampler is not None:\n",
    "            source, target, is_mirrored = self.pair_sampler(self.device)\n",
    "        else:\n",
    "            raise ValueError(\"No pair provided. Pass options={pair: (...)} or set pair_sampler.\")\n",
    "\n",
    "        self._set_pair(source, target, is_mirrored)\n",
    "        info = {\"angle\": self.current_angle}\n",
    "        return self._obs(), info\n",
    "\n",
    "    def step(self, action: int):\n",
    "        terminated = False\n",
    "        reward = 0.0\n",
    "        err = self._alignment_error()\n",
    "\n",
    "        if action == 0 or action == 1:\n",
    "            delta = -10.0 if action == 0 else 10.0\n",
    "            self.current_angle = (self.current_angle + delta) % 360.0\n",
    "            self.current_source = rotate_tensor(self.base_source, self.current_angle)\n",
    "            err = self._alignment_error()\n",
    "            reward = -float(err.detach())\n",
    "            self._update_no_improve(err)\n",
    "        elif action == 2 or action == 3:\n",
    "            delta = -5.0 if action == 2 else 5.0\n",
    "            self.current_angle = (self.current_angle + delta) % 360.0\n",
    "            self.current_source = rotate_tensor(self.base_source, self.current_angle)\n",
    "            err = self._alignment_error()\n",
    "            reward = -float(err.detach())\n",
    "            self._update_no_improve(err)\n",
    "        elif action == 4 or action == 5:\n",
    "            delta = -1.0 if action == 4 else 1.0\n",
    "            self.current_angle = (self.current_angle + delta) % 360.0\n",
    "            self.current_source = rotate_tensor(self.base_source, self.current_angle)\n",
    "            err = self._alignment_error()\n",
    "            reward = -float(err.detach())\n",
    "            self._update_no_improve(err)\n",
    "        elif action == 6:\n",
    "            if err < self.epsilon:\n",
    "                is_match = (not self.is_mirrored)\n",
    "                reward = 100.0 if is_match else -100.0\n",
    "                terminated = True\n",
    "            else:\n",
    "                reward = -float(err.detach())\n",
    "                self._update_no_improve(err)\n",
    "        elif action == 7:\n",
    "            if self.no_improve_steps >= self.mismatch_patience:\n",
    "                reward = 100.0 if self.is_mirrored else -100.0\n",
    "                terminated = True\n",
    "            else:\n",
    "                reward = -float(err.detach())\n",
    "                self._update_no_improve(err)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid action: {action}\")\n",
    "\n",
    "        self.step_count += 1\n",
    "        truncated = (self.step_count >= self.max_steps) and (not terminated)\n",
    "\n",
    "        info = {\n",
    "            \"angle\": self.current_angle,\n",
    "            \"error\": float(err.detach().cpu()),\n",
    "            \"is_mirrored\": self.is_mirrored,\n",
    "            \"no_improve_steps\": self.no_improve_steps,\n",
    "        }\n",
    "        return self._obs(), float(reward), terminated, truncated, info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dad537",
   "metadata": {},
   "source": [
    "With the environment in place, we can plug in **Stable-Baselines3 PPO** directly. This mirrors the baseline\n",
    "usage from the SB3 docs. We keep hyperparameters default for now (except total timesteps), which is the\n",
    "simplest usable PPO setup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3ab6da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 169      |\n",
      "|    ep_rew_mean     | -8.92    |\n",
      "| time/              |          |\n",
      "|    fps             | 148      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 166         |\n",
      "|    ep_rew_mean          | 0.167       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011227023 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.06       |\n",
      "|    explained_variance   | -0.00808    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0757      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | 0.00953     |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 165          |\n",
      "|    ep_rew_mean          | -0.927       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0143400775 |\n",
      "|    clip_fraction        | 0.198        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.06        |\n",
      "|    explained_variance   | 0.0412       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 47           |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | 0.00342      |\n",
      "|    value_loss           | 79.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 167         |\n",
      "|    ep_rew_mean          | -1.54       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029226126 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.02       |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.79        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | 0.0258      |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 166         |\n",
      "|    ep_rew_mean          | -1.11       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.063770264 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.02       |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | 0.00754     |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 165         |\n",
      "|    ep_rew_mean          | 1.46        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030571692 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.01       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.816       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | 0.00553     |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 165         |\n",
      "|    ep_rew_mean          | 0.154       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031343374 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.96       |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.8         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.000452   |\n",
      "|    value_loss           | 58.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 166         |\n",
      "|    ep_rew_mean          | -1.37       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039863214 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.96       |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 6.76        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 166         |\n",
      "|    ep_rew_mean          | -1.86       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025285127 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.99       |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.1        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00864    |\n",
      "|    value_loss           | 30.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 165        |\n",
      "|    ep_rew_mean          | -1.88      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 133        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03221473 |\n",
      "|    clip_fraction        | 0.299      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.01      |\n",
      "|    explained_variance   | 0.128      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.693      |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    value_loss           | 4.33       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 164        |\n",
      "|    ep_rew_mean          | -0.547     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 154        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 146        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02380491 |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.03      |\n",
      "|    explained_variance   | 0.181      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.73       |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | 0.0276     |\n",
      "|    value_loss           | 18.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 163         |\n",
      "|    ep_rew_mean          | -0.0663     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035954818 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.95       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.822       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | 0.00662     |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 160         |\n",
      "|    ep_rew_mean          | -3.31       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017882787 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00218    |\n",
      "|    value_loss           | 38.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 162        |\n",
      "|    ep_rew_mean          | -5.66      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 132        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 216        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08419779 |\n",
      "|    clip_fraction        | 0.43       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.91      |\n",
      "|    explained_variance   | 0.368      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.89       |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | 0.0354     |\n",
      "|    value_loss           | 45.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 155         |\n",
      "|    ep_rew_mean          | 4.44        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044378873 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.87        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 4.96        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 153       |\n",
      "|    ep_rew_mean          | 6.55      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 133       |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 246       |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0291933 |\n",
      "|    clip_fraction        | 0.381     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.89     |\n",
      "|    explained_variance   | 0.189     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 15.8      |\n",
      "|    n_updates            | 150       |\n",
      "|    policy_gradient_loss | 0.0136    |\n",
      "|    value_loss           | 95.9      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 147         |\n",
      "|    ep_rew_mean          | 7.71        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036216922 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.1        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | 0.00192     |\n",
      "|    value_loss           | 38.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 147        |\n",
      "|    ep_rew_mean          | 5.74       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 272        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08347538 |\n",
      "|    clip_fraction        | 0.389      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.82      |\n",
      "|    explained_variance   | 0.453      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.25       |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.00334   |\n",
      "|    value_loss           | 20.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 143         |\n",
      "|    ep_rew_mean          | 7.76        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 286         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043050244 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.94        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | 0.0139      |\n",
      "|    value_loss           | 47.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 144         |\n",
      "|    ep_rew_mean          | 10.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036399033 |\n",
      "|    clip_fraction        | 0.415       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.8         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | 0.0173      |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 138         |\n",
      "|    ep_rew_mean          | 15.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 138         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 311         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056412302 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.301       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | 0.022       |\n",
      "|    value_loss           | 8.36        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 144        |\n",
      "|    ep_rew_mean          | 7.37       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 139        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 324        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07574102 |\n",
      "|    clip_fraction        | 0.486      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.45      |\n",
      "|    explained_variance   | 0.456      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 20.4       |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | 0.0256     |\n",
      "|    value_loss           | 51.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 144         |\n",
      "|    ep_rew_mean          | 4.61        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 336         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045491166 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.23        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 147         |\n",
      "|    ep_rew_mean          | 6.81        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 349         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054843377 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.79        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 146         |\n",
      "|    ep_rew_mean          | 8.63        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 362         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030413125 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x12f81a4b0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(0)\n",
    "\n",
    "H, W = 64, 64\n",
    "image_shape = (3, H, W)\n",
    "\n",
    "sampler = make_pair_sampler(image_shape=image_shape, mirror_prob=0.5, angle_step=5.0)\n",
    "\n",
    "env = RotationEnv(\n",
    "    image_shape=image_shape,\n",
    "    max_steps=180,\n",
    "    epsilon=0.03,\n",
    "    device=device,\n",
    "    pair_sampler=sampler,\n",
    ")\n",
    "\n",
    "model = PPO(\n",
    "    \"CnnPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    device=\"auto\",\n",
    "    policy_kwargs={\"normalize_images\": False},\n",
    ")\n",
    "\n",
    "# Train (increase total_timesteps for better performance)\n",
    "model.learn(total_timesteps=50_000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b7d237",
   "metadata": {},
   "source": [
    "Finally, a tiny evaluation loop to get a quick sanity check on reward and correctness. We'll count a\n",
    "\"success\" when the episode terminates with a positive terminal reward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cfbe30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean episode reward: 2.79\n",
      "Success rate: 16.67%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_eval_episodes = 30\n",
    "success = 0\n",
    "rewards = []\n",
    "\n",
    "for _ in range(n_eval_episodes):\n",
    "    obs, _ = env.reset()\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    ep_reward = 0.0\n",
    "    last_reward = 0.0\n",
    "\n",
    "    while not (terminated or truncated):\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, info = env.step(int(action))\n",
    "        ep_reward += float(reward)\n",
    "        last_reward = float(reward)\n",
    "\n",
    "    rewards.append(ep_reward)\n",
    "    if terminated and last_reward > 0:\n",
    "        success += 1\n",
    "\n",
    "print(f\"Mean episode reward: {np.mean(rewards):.2f}\")\n",
    "print(f\"Success rate: {success / n_eval_episodes:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visual-reasoning (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
